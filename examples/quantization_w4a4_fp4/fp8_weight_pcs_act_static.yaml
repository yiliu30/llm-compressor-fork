quantization_stage:
  quantization_modifiers:
    QuantizationModifier:
      ignore: ["lm_head", "re:.*mlp\\.gate.*"]
      config_groups:
        group_0:
          weights:
            num_bits: 8
            type: "float"
            symmetric: true
            strategy: "channel"
            dynamic: false
          targets: ["Linear"]
          input_activations:
            num_bits: 8
            type: "float"
            symmetric: true
            strategy: "tensor"
            dynamic: false